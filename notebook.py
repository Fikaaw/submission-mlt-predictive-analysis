# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sQHZ0ForpUOs0hje_vySkDRTRsEk6cCt

# **Predictive Analytics - Prediksi Obesitas**

## Deskripsi Proyek

Proyek ini bertujuan untuk memprediksi tingkat obesitas berdasarkan berbagai fitur seperti . Data  akan digunakan untuk melatih beberapa model machine learning, termasuk Decision Tree Classifier, XGBoost, Random Forest Classifier. Hasil dari model-model tersebut akan dibandingkan dan dievaluasi untuk memilih model yang paling tepat dalam memprediksi tingkat obesitas dengan tingkat kesalahan yang minimal dan val.

*Dataset yang digunakan pada proyek ini:*  
https://www.kaggle.com/competitions/playground-series-s4e2/data

| **Variable**                  | **Description**                                 | **Variable**        | **Description**                          |
|:------------------------------|:------------------------------------------------|:--------------------|:-----------------------------------------|
| **ID**                        | Unique identifier                               | **NCP**             | Number of main meals                     |
| **Gender**                    | Gender                                          | **CAEC**            | Consumption of food between meals        |
| **Age**                       | Age (years)                                     | **SMOKE**           | Smoker or not                            |
| **Height**                    | Height (meters)                                 | **CH2O**            | Consumption of water daily               |
| **Weight**                    | Weight (kilograms)                              | **SCC**             | Calories consumption monitoring          |
| **family_history_with_overweight** | Family history of overweight            | **FAF**             | Physical activity frequency              |
| **FAVC**                      | Frequent consumption of high caloric food       | **TUE**             | Time using technology devices            |
| **FCVC**                      | Frequency of consumption of vegetables          | **CALC**            | Consumption of alcohol                   |
| **MTRANS**                    | Transportation used                             | **NObeyesdad**     | Obesity level deducted                   |

## Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import warnings
warnings.filterwarnings("ignore")

"""## Data Understanding

### Gathering Data
"""

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

# return the first three rows of training data
train.head(3)

# return the first three rows of testing data
test.head(3)

"""### Assessing Data

#### Dataset Information
"""

# training set shape
train.shape

train.info()

"""#### Checking Missing Value

"""

# checking if there are missing values
print("Is there any missing values?")
train.isna().any()

"""#### Checking Duplicate Data

"""

# checking if there duplicated data
print("The number of duplicated data:", train.duplicated().sum())

"""#### Statistic Description"""

# summary statistics
train.describe().transpose()

# calculate the BMI value
train["BMI"] = train["Weight"] / train["Height"]**2

"""### Exploratory Data Analysis (EDA)

#### 1. Correlation Matrix
"""

# correlation matrix
corr = train.select_dtypes("number").corr()

sns.heatmap(corr, annot=True, cmap="RdBu")
plt.title("Correlation Matrix")
plt.show()

"""#### 2. Data Distibution"""

# Visualisasi fitur numerik untuk melihat masing-masing histogram
train.hist(bins=50, figsize=(20,15))
plt.show()

train["Gender"].value_counts().plot(kind="pie", startangle=90, autopct='%1.1f%%', labels=None)

plt.ylabel("")
plt.legend(train["Gender"].value_counts().index, loc="best")
plt.title("Gender Distribution")

plt.show()

train.groupby("NObeyesdad")["BMI"].mean().sort_values(ascending=True).plot(kind="barh")
plt.title("Average BMI by Obesity Level")
plt.xlabel("Average BMI")
plt.show()

"""## Data Preparation

### Standarisasi Fitur dan Encoding Data Kategorikal
"""

# subsetting the dataset into features and label
X = train.drop("NObeyesdad", axis=1).copy()
y = train["NObeyesdad"].copy()

# splitting the dataset into training and testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)

# select numerical columns
numerical_columns = X_train.select_dtypes("number").columns

# select categorical columns
categorical_columns = X_train.select_dtypes(exclude=["number"]).columns

# preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numerical_columns),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_columns)
    ]
)

# instantiate the pipeline
pipeline = Pipeline([
    ("preprocessor", preprocessor)
])

"""## Model Development

### Mempersiapkaan dataframe untuk analisis model
"""

# transforming the training and testing features
X_train_cleaned = pipeline.fit_transform(X_train)
X_test_cleaned = pipeline.transform(X_test)

"""### Algoritma Decision Tree"""

# Melatih model Decision Tree
dec_tree = DecisionTreeClassifier(random_state=2024)
dec_tree.fit(X_train_cleaned, y_train)

# Membuat prediksi
y_pred_train = dec_tree.predict(X_train_cleaned)
y_pred_test = dec_tree.predict(X_test_cleaned)

# Menghitung metrik untuk data training
print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

# Menampilkan laporan klasifikasi lengkap
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

"""### Algorima XGBoost"""

# Melatih model XGBoost
xgb = GradientBoostingClassifier()
xgb.fit(X_train_cleaned, y_train)

# Membuat prediksi
y_pred_train = xgb.predict(X_train_cleaned)
y_pred_test = xgb.predict(X_test_cleaned)

# Menghitung metrik untuk data training
print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

# Menampilkan laporan klasifikasi lengkap
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

"""### RandomForestClassifier"""

# Melatih model Random Forest
random_forest = RandomForestClassifier()
random_forest.fit(X_train_cleaned, y_train)

# Membuat prediksi
y_pred_train = random_forest.predict(X_train_cleaned)
y_pred_test = random_forest.predict(X_test_cleaned)

# Menghitung metrik untuk data training
print("Training Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train))
print("Precision:", precision_score(y_train, y_pred_train, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train, average='weighted'))

print("\nTesting Metrics:")
print("Accuracy:", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test, average='weighted'))
print("Recall:", recall_score(y_test, y_pred_test, average='weighted'))
print("F1-score:", f1_score(y_test, y_pred_test, average='weighted'))

# Menampilkan laporan klasifikasi lengkap
print("\nClassification Report:")
print(classification_report(y_test, y_pred_test))

"""### Support Vector Machine (SVM)"""

svm = SVC(kernel='rbf', random_state=2024)
svm.fit(X_train_cleaned, y_train)

y_pred_train_svm = svm.predict(X_train_cleaned)
y_pred_test_svm = svm.predict(X_test_cleaned)

print("SVM Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_svm))
print("Precision:", precision_score(y_train, y_pred_train_svm, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_svm, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_svm, average='weighted'))
print("\nTesting Metrics:")
print(classification_report(y_test, y_pred_test_svm))

# Import library yang diperlukan
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

"""### Logistic Regression"""

log_reg = LogisticRegression(multi_class='multinomial', max_iter=1000)
log_reg.fit(X_train_cleaned, y_train)

y_pred_train_log = log_reg.predict(X_train_cleaned)
y_pred_test_log = log_reg.predict(X_test_cleaned)

print("\nLogistic Regression Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_log))
print("Precision:", precision_score(y_train, y_pred_train_log, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_log, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_log, average='weighted'))
print("\nTesting Metrics:")
print(classification_report(y_test, y_pred_test_log))

"""### Lightgbm"""

pip install lightgbm

import lightgbm as lgb
lgb_model = lgb.LGBMClassifier()
lgb_model.fit(X_train_cleaned, y_train)

y_pred_train_lgb = lgb_model.predict(X_train_cleaned)
y_pred_test_lgb = lgb_model.predict(X_test_cleaned)

print("\nLightGBM Classification Report:")
print("\nTraining Metrics:")
print("Accuracy:", accuracy_score(y_train, y_pred_train_lgb))
print("Precision:", precision_score(y_train, y_pred_train_lgb, average='weighted'))
print("Recall:", recall_score(y_train, y_pred_train_lgb, average='weighted'))
print("F1-score:", f1_score(y_train, y_pred_train_lgb, average='weighted'))
print("\nTesting Metrics:")
print(classification_report(y_test, y_pred_test_lgb))

"""### Evaluasi Model

- Pengembangan model prediktif obesitas dapat membantu identifikasi individu berisiko tinggi.
- Performa terbaik: LightGBM memberikan akurasi tertinggi pada data testing dengan keseimbangan baik antara training dan testing.
- Overfitting: Decision Tree dan Random Forest cenderung overfit pada data training.
- Keandalan: XGBoost dan LightGBM lebih andal dalam mengatasi data yang kompleks.
"""